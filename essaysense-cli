#!/usr/bin/env python3

# This is an executable file of EssaySense project, providing a command line
# interface. Note that the first line declares the intepreter in POSIX
# environments. So, on Windows, we recommand using it via bash-like environments
# like Git Bash.

"""Command Line Interface of EssaySense project.

This is an executable file for EssaySense project in this preview version. You
can run pre-trained models to score an essay text, train neural network models
based on new datasets, or evaluate these models. For usage help, please run the following command in your system's command line environment:

    $ ./essaysense-cli --help

For more information, please see README.md.
"""

# This project uses click (see http://click.pocoo.org/6/)
# to create a command line interface.
import click
# Version tag corresponding to the main package.
__version__ = "0.0.4"

# Version printing function.
def print_version(ctx, param, value):
    """Callback function that printing the version of the app."""
    if not value or ctx.resilient_parsing:
        return
    click.echo("EssaySense Project: version " + __version__)
    ctx.exit()

# Model importing function.
def import_model(model_name, prompt, mode):
    import essaysense
    try:
        model_bundle = essaysense.avaliable_models[model_name]
    except KeyError:
        click.echo("[Error] Model '{}' does not exist.".format(model_name))
        click.echo("[Avaliable models]")
        for i, model_name in enumerate(essaysense.avaliable_models.keys()):
            click.echo("{}: ".format(i+1) + model_name)
        return

    glove_table = essaysense.datasets.load_glove()
    asap_train = essaysense.datasets.load_asap(
        path=essaysense.configs.paths.asap_train,
        domain_id=prompt)
    train_set = model_bundle["train"](
        hyperparameters=essaysense.configs.hyperparameters,
        lookup_table=glove_table,
        raw_train_set=asap_train)

    if mode == "train":
        asap_dev = essaysense.datasets.load_asap(
            path=essaysense.configs.paths.asap_dev,
            domain_id=prompt)
        dev_set = model_bundle["test"](
            hyperparameters=essaysense.configs.hyperparameters,
            lookup_table=glove_table,
            raw_test_set=asap_dev)
        model = model_bundle["model"](
            hyperparameters=essaysense.configs.hyperparameters,
            train_set=train_set,
            test_set=dev_set,
            domain_id=prompt)
        return model
    elif mode == "evaluate":
        asap_test = essaysense.datasets.load_asap(
            path=essaysense.configs.paths.asap_test,
            domain_id=prompt)
        test_set = model_bundle["test"](
            hyperparameters=essaysense.configs.hyperparameters,
            lookup_table=glove_table,
            raw_test_set=asap_test)
        model = model_bundle["model"](
            hyperparameters=essaysense.configs.hyperparameters,
            train_set=train_set,
            test_set=test_set,
            domain_id=prompt)
        return model


# Command Line Interface Construction
@click.option("-v", "--version", is_flag=True, callback=print_version,
              expose_value=False, is_eager=True, help="Show project version.")
@click.group()
def cli():
    pass  # main process, grouping commands later.

@click.command(help="show all avaliable model names.")
def show():
    click.echo("[Loading] Avaliable models...")
    import essaysense
    for i, model_name in enumerate(essaysense.avaliable_models.keys()):
        click.echo("{}: ".format(i+1) + model_name)

@click.command(help="Train an automated essay scoring model.")
@click.argument("model_name")
@click.option("-p", "--prompt", default=1, help='Choose a prompt to run')
def train(model_name, prompt):
    model = import_model(model_name, prompt, mode="train")
    model.train()
    return

@click.command(help="Evaluate a pre-trained EssaySense model.")
@click.argument("model_name")
@click.option("-p", "--prompt", default=1, help='Choose a prompt to run')
def evaluate(model_name, prompt):
    model = import_model(model_name, prompt, mode="evaluate")
    model.evaluate()
    return

@click.command(help="Visualize the a model via TensorBoard.")
@click.argument("model_name")
@click.option("-p", "--prompt", default=1, help='Choose a prompt to run')
def visualize(model_name, prompt):
    model = import_model(model_name, prompt, mode="evaluate")
    model.visualize()
    return

cli.add_command(show)
cli.add_command(train)
cli.add_command(evaluate)
cli.add_command(visualize)

if __name__ == "__main__":
    cli()
